{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "import subprocess\n",
    "import os\n",
    "import json\n",
    "import geopandas as gpd\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resolution = \"50\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = f\"/home/data/national_fema_floodmap/rasters/{resolution}m\"\n",
    "if not os.path.exists(folder_path):\n",
    "    os.mkdir(folder_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "raster100y =  f\"{folder_path}/national_fema_raster_100y_{resolution}m.tiff\"\n",
    "raster500y =  f\"{folder_path}/national_fema_raster_500y_{resolution}m.tiff\"\n",
    "raster_combined = f\"{folder_path}/national_fema_raster_combined_{resolution}m.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: Error occurred in /home/conda/feedstock_root/build_artifacts/gdal-split_1704802395302/work/ogr/ogrsf_frmts/openfilegdb/filegdbindex.cpp at line 800\n",
      "ERROR 1: Error occurred in /home/conda/feedstock_root/build_artifacts/gdal-split_1704802395302/work/ogr/ogrsf_frmts/openfilegdb/filegdbindex.cpp at line 800\n",
      "Warning 1: organizePolygons() received a polygon with more than 100 parts. The processing may be really slow.  You can skip the processing by setting METHOD=SKIP, or only make it analyze counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock wise defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gdal_rasterize', '-tr', '30', '30', '-sql', \"SELECT * FROM USA_Flood_Hazard_Reduced_Set WHERE esri_symbology = '1% Annual Chance Flood Hazard'\", '-burn', '1', '-ot', 'Byte', '-co', 'COMPRESS=LZW', '/home/data/national_fema_floodmap/efa6409b-9dab-4b36-b0aa-8641f1b26b6e.gdb', '/home/data/national_fema_floodmap/rasters/30m/national_fema_raster_100y_30m.tiff'], returncode=0)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the command as a list of arguments\n",
    "command = [\n",
    "    \"gdal_rasterize\",\n",
    "    \"-tr\", resolution, resolution,\n",
    "    \"-sql\", \"SELECT * FROM USA_Flood_Hazard_Reduced_Set WHERE esri_symbology = '1% Annual Chance Flood Hazard'\",\n",
    "    \"-burn\", \"1\",\n",
    "    \"-ot\", \"Byte\",\n",
    "    \"-co\", \"COMPRESS=LZW\",\n",
    "    \"/home/data/national_fema_floodmap/efa6409b-9dab-4b36-b0aa-8641f1b26b6e.gdb\",\n",
    "    raster100y\n",
    "]\n",
    "\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR 1: Error occurred in /home/conda/feedstock_root/build_artifacts/gdal-split_1704802395302/work/ogr/ogrsf_frmts/openfilegdb/filegdbindex.cpp at line 800\n",
      "ERROR 1: Error occurred in /home/conda/feedstock_root/build_artifacts/gdal-split_1704802395302/work/ogr/ogrsf_frmts/openfilegdb/filegdbindex.cpp at line 800\n",
      "Warning 1: organizePolygons() received a polygon with more than 100 parts. The processing may be really slow.  You can skip the processing by setting METHOD=SKIP, or only make it analyze counter-clock wise parts by setting METHOD=ONLY_CCW if you can assume that the outline of holes is counter-clock wise defined\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gdal_rasterize', '-tr', '30', '30', '-sql', \"SELECT * FROM USA_Flood_Hazard_Reduced_Set WHERE esri_symbology = '0.2% Annual Chance Flood Hazard'\", '-burn', '1', '-ot', 'Byte', '-co', 'COMPRESS=LZW', '/home/data/national_fema_floodmap/efa6409b-9dab-4b36-b0aa-8641f1b26b6e.gdb', '/home/data/national_fema_floodmap/rasters/30m/national_fema_raster_500y_30m.tiff'], returncode=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Define the command as a list of arguments\n",
    "command = [\n",
    "    \"gdal_rasterize\",\n",
    "    \"-tr\", resolution, resolution,\n",
    "    \"-sql\", \"SELECT * FROM USA_Flood_Hazard_Reduced_Set WHERE esri_symbology = '0.2% Annual Chance Flood Hazard'\",\n",
    "    \"-burn\", \"1\",\n",
    "    \"-ot\", \"Byte\",\n",
    "    \"-co\", \"COMPRESS=LZW\",\n",
    "    \"/home/data/national_fema_floodmap/efa6409b-9dab-4b36-b0aa-8641f1b26b6e.gdb\",\n",
    "    raster500y\n",
    "]\n",
    "\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/canyon/miniconda3/envs/myenv/lib/python3.9/site-packages/osgeo/gdal.py:312: FutureWarning: Neither gdal.UseExceptions() nor gdal.DontUseExceptions() has been explicitly called. In GDAL 4.0, exceptions will be enabled by default.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['/home/canyon/miniconda3/envs/myenv/bin/python', '-m', 'osgeo_utils.gdal_calc', '-A', '/home/data/national_fema_floodmap/rasters/30m/national_fema_raster_100y_30m.tiff', '-B', '/home/data/national_fema_floodmap/rasters/30m/national_fema_raster_500y_30m.tiff', '--outfile=/home/data/national_fema_floodmap/rasters/30m/national_fema_raster_combined_30m.tiff', '--calc=\"(A>0)*1 + (B>0)*(A<=0)*2\"', '--NoDataValue=0', '--config', 'CHECK_DISK_FREE_SPACE', 'FALSE', '--co', 'COMPRESS=LZW', '--overwrite'], returncode=0)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Construct the command using sys.executable to ensure the correct Python interpreter is used\n",
    "command = [\n",
    "    sys.executable, \"-m\", \"osgeo_utils.gdal_calc\",\n",
    "    \"-A\", raster100y,\n",
    "    \"-B\", raster500y,\n",
    "    \"--outfile=\" + raster_combined,\n",
    "    \"--calc=\\\"(A>0)*1 + (B>0)*(A<=0)*2\\\"\",  # Conditional calculation\n",
    "    \"--NoDataValue=0\",\n",
    "    \"--config\", \"CHECK_DISK_FREE_SPACE\", \"FALSE\",\n",
    "    \"--co\", \"COMPRESS=LZW\",\n",
    "    \"--overwrite\"\n",
    "]# Execute the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open(\"/home/canyon/TOP-Sprint/analysis/src/config.json\") as f:\n",
    "        config = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_national_boundary(config):\n",
    "    gdfs = []\n",
    "    cities_base_path = f\"{config['base_path']}/cities/\"\n",
    "    for city in next(os.walk(cities_base_path))[1]:\n",
    "        try:\n",
    "            print(f\"Reading data for {city}\")\n",
    "            tracts = gpd.read_file(f\"{cities_base_path}/{city}/census/geo/tracts.geojson\")\n",
    "            tracts['to_merge'] = 1\n",
    "    \n",
    "            gdf_extent = tracts.dissolve(by='to_merge')\n",
    "            gdfs.append(gdf_extent)\n",
    "        except:\n",
    "            print(f\"No geography for {city}\")\n",
    "            continue\n",
    "    national_gdf = pd.concat(gdfs)\n",
    "\n",
    "    national_gdf = national_gdf.reset_index().dissolve(by='to_merge')\n",
    "    return national_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data for C1382\n",
      "Reading data for C1074\n",
      "Reading data for C3806\n",
      "Reading data for C3108\n",
      "Reading data for C4014\n",
      "Reading data for C4186\n",
      "Reading data for C4090\n",
      "Reading data for C3538\n",
      "Reading data for C4174\n",
      "Reading data for C4194\n",
      "Reading data for C2342\n",
      "Reading data for C1974\n",
      "Reading data for C2554\n",
      "Reading data for C1486\n",
      "Reading data for C4790\n",
      "Reading data for C3310\n",
      "Reading data for C4530\n",
      "Reading data for C3674\n",
      "Reading data for C2726\n",
      "Reading data for C1206\n",
      "Reading data for C1978\n",
      "Reading data for C1698\n",
      "Reading data for C2690\n",
      "Reading data for C3114\n",
      "Reading data for C1446\n",
      "Reading data for C4934\n",
      "Reading data for C1258\n",
      "Reading data for C1982\n",
      "Reading data for C3346\n",
      "Reading data for C4118\n",
      "Reading data for C2814\n",
      "Reading data for C1674\n",
      "Reading data for C3958\n",
      "Reading data for C3654\n",
      "Reading data for C2982\n",
      "Reading data for C3562\n",
      "Reading data for C4038\n",
      "Reading data for C1538\n",
      "Reading data for C1746\n",
      "Reading data for C1714\n",
      "Reading data for C1814\n",
      "Reading data for C3642\n",
      "Reading data for C3890\n",
      "Reading data for C3798\n",
      "Reading data for C3830\n",
      "Reading data for C3930\n",
      "Reading data for C2486\n",
      "Reading data for C4162\n",
      "Reading data for C4006\n",
      "Reading data for C3334\n",
      "Reading data for C4726\n",
      "Reading data for C3498\n",
      "Reading data for C1242\n",
      "Reading data for C4170\n",
      "Reading data for C4266\n",
      "Reading data for C2642\n",
      "Reading data for C1910\n"
     ]
    }
   ],
   "source": [
    "out = create_national_boundary(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "boundary_path = \"/home/data/national_fema_floodmap/national_boundaries.geojson\" \n",
    "out.to_file(boundary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clipped_raster_path = f\"{folder_path}/national_fema_raster_combined_clipped.tiff\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/data/national_fema_floodmap/rasters/50m/national_fema_raster_combined_50m.tiff'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raster_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating output file that is 118577P x 65279L.\n",
      "Processing /home/data/national_fema_floodmap/rasters/50m/national_fema_raster_combined_50m.tiff [1/1] : 0Using internal nodata values (e.g. 0) for image /home/data/national_fema_floodmap/rasters/50m/national_fema_raster_combined_50m.tiff.\n",
      "...10...20...30...40...50...60...70...80...90...100 - done.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CompletedProcess(args=['gdalwarp', '-cutline', '/home/data/national_fema_floodmap/national_boundaries.geojson', '-crop_to_cutline', '-dstalpha', '-co', 'COMPRESS=LZW', '-co', 'PREDICTOR=2', '-co', 'TILED=YES', '/home/data/national_fema_floodmap/rasters/50m/national_fema_raster_combined_50m.tiff', '/home/data/national_fema_floodmap/rasters/50m/national_fema_raster_combined_clipped.tiff'], returncode=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "command = [\n",
    "    \"gdalwarp\", \"-cutline\",\n",
    "    boundary_path, \"-crop_to_cutline\",\n",
    "    \"-dstalpha\", \"-co\", \"COMPRESS=LZW\", \"-co\", \"PREDICTOR=2\", \"-co\", \"TILED=YES\",\n",
    "    raster_combined,\n",
    "    clipped_raster_path\n",
    "]\n",
    "\n",
    "# Execute the command\n",
    "subprocess.run(command, check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TOP-Sprint-lAvM2-mU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
